{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report\n",
    "## NCAA Predictor\n",
    "Brandon Clark and Ben Comer\n",
    "Spring 2021, May 5\n",
    "CPSC322 - Data Science Algorithms (Sprint)\n",
    "Final Project\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use Men's Basketball NCAA Statistics from the 2020-21 season to try to come up with classifiers that would determine winning percentage of the individual teams based on their statistics in the areas studied.\n",
    "\n",
    "We found that there were several moderately strong indicators of winning percentage, particularly in Rebound margin and in Effective Field Goal Percentage, which we will cover further down in this report. We found that Scoring Margin was a fantastic predictor thereto, so much so that we dropped it as a used attribute towards finding interesting results.\n",
    "\n",
    "## Data Analysis\n",
    "### Preface\n",
    "We'll be using the following statistics, as noted by the side-by-side notation in LaTeX:\n",
    "- $PTS$: The number of points the team scored.\n",
    "- $PTS_{opp}$: The number of points the team allowed.\n",
    "- $3PM$: The number of 3-Point shots made by the team.\n",
    "- $2PM$: The number of 2-Point shots made by the team.\n",
    "- $FGA$: The number of Field Goals (3's and 2's) attempted by the team.\n",
    "- $REB$: The number of rebounds the team recovered.\n",
    "- $REB_{opp}$: The number of rebounds the team's opponent recovered.\n",
    "- $SPG$: The number of steals per game the team got.\n",
    "- $BPG$: The number of blocks per game the team achieved.\n",
    "- $W$: The number of wins a team has on the season.\n",
    "- $L$: The number of losses a team has on the season.\n",
    "- $G$: The number of games a team played on the season.\n",
    "\n",
    "Additionally, if you wish to see the data we used in a csv format, check out [NCAA_Statistics.csv](input_data/NCAA_Statistics.csv).\n",
    "\n",
    "### Attribute Selection\n",
    "There are four attributes used in the classification schemas, and one classification. They are as follows:\n",
    "\n",
    "- _**Scoring Margin**_: $SCM = \\frac{PTS}{PTS_{opp}}$\n",
    "The margin of a team's scored points to their opponent's scored points. Average should be 1.0, when weighting for points scored for the whole game (which we are not doing).\n",
    "\n",
    "- _**Effective Field Goal Percentage**_: $EFG\\% = \\frac{3PM * 1.5 + 2PM}{FGA}$\n",
    "A team's likelihood of making a given shot given historical data, with added weight to three pointers (for their point value). Has no default average.\n",
    "\n",
    "- _**Rebound Margin**_: $RBM = \\frac{REB}{REB_{opp}}$\n",
    "A team's ratio of rebounds taken versus their opponent. Average should be 1.0, given weight for number of rebounds recovered for the whole game.\n",
    "\n",
    "- _**Steals Plus Blocks Per Game**_: $SPB = SPG + BPG$\n",
    "The total number of steals and blocks a team gets in a game. No default average.\n",
    "\n",
    "And the classification...\n",
    "- _**Winning Percentage**_: $W\\% = \\frac{W}{G}$\n",
    "The percentage of games a team played over the season that they won. Expressed as a value $x$ such that $0 \\le x \\le 1$.\n",
    "\n",
    "You can find all of these data in [NCAA_Statistics_Parsed.csv](input_data/NCAA_Statistics_Parsed.csv), in the input_data folder. To see the code used, check out [data_parser.ipynb](data_parser.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "We normalized using min-max scaling on each attribute, from its minimum to its maximum. The exception was in the winning percentage, which we normalized along 0 to 1, the possible minimum and maximum for the value, and one acheivable historically, in both directions.\n",
    "\n",
    "You can see the result of this in [NCAA_Statistics_Normalized.csv](input_data/NCAA_Statistics_Normalized.csv).\n",
    "\n",
    "### Discretization\n",
    "We checked a ton of splitting methods here, and upon looking at a ton of ditribution charts and generation of many decision trees, we decided to split each attribute into 4 discrete labels. We also decided here to drop the Scoring Margin feature, as we felt it was not helpful, and if one had the information thereof, it would be trivial to take a stab at what classification each deserves. With this discretization schema, we were able to generate interesting data, as seen below, further down.\n",
    "\n",
    "Upon this Discretization, we got [NCAA_Statistics_44444.csv](input_data/NCAA_Statistics_44444.csv).\n",
    "\n",
    "See how we did both of these tasks in [norm_and_disc.ipynb](norm_and_disc.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "Using the data at the end of [EDA.ipynb](EDA.ipynb)..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Median of Scoring Margin: 1.0170782550727964\n",
    "Mean of Scoring Margin: 1.0162707010296386\n",
    "SD of Scoring Margin: 0.09926059680557543\n",
    "\n",
    "Median of eFG%: 0.5023921619007314\n",
    "Mean of eFG%: 0.5031580512596515\n",
    "SD of eFG%: 0.03096279413298644\n",
    "\n",
    "Median of SPG+BPG: 9.594117647058823\n",
    "Mean of SPG+BPG: 9.672694427382291\n",
    "SD of SPG+BPG: 1.6354833087724625\n",
    "\n",
    "Median of Rebound Margin: 1.008747777204153\n",
    "Mean of Rebound Margin: 1.01716812779002\n",
    "SD of Rebound Margin: 0.1179884096948017\n",
    "\n",
    "Median of Win Percentage: 52.0\n",
    "Mean of Win Percentage: 50.55472529117821\n",
    "SD of Win Percentage: 18.29008236426564"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing this, our earlier inferences align with the proof here.\n",
    "\n",
    "### Distributions and Regression Analysis\n",
    "We made several histograms for each attribute to gather the frequency between certain bounds, and linear regression plots to show our work. Rather than copy over the work, [here's a link to EDA.ipynb instead](EDA.ipynb).\n",
    "\n",
    "Some analysis is twofold, here. For one, it's visible to the naked eye that these are normal distributions, skewed as they may be. The bell curve shape is obvious enough. Second, we have one amazing correlative stat, being Scoring Margin, with around a .9 correlation coefficient, two moderately good ones in Rebound Margin and Effective Field Goal Percentage, each with around .6 r, and a poor one, in Steals + Bloacks, which has around a .2 r.\n",
    "\n",
    "## Classification\n",
    "You can see all of our classification work in [classification_eval.ipynb](classification_eval.ipynb), alongside the confusion matrices and the like listed below.\n",
    "\n",
    "### kNN Classification\n",
    "We used our standard kNN classification upon the dataset, with n_neighbors=10. The kNN performed without issue using stratified k-fold cross-validation with 10 folds (we'll use this for all our classifiers). We got the following info:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "KNN: accuracy = 0.5294117647058824, error rate = 0.47058823529411764\n",
    "\n",
    "  Win% Tier    1    2    3    4    total    Recognition (%)\n",
    "-----------  ---  ---  ---  ---  -------  -----------------\n",
    "          1   24    9    1    0       34           70.5882\n",
    "          2   28   69   19    0      116           59.4828\n",
    "          3    2   68   84    3      157           53.5032\n",
    "          4    0    8   22    3       33            9.09091"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 53% accuracy rate is nothing to scoff at with 4 classification possibilities. Notably, this classifier was excellent in detecting bad teams; A 71% recognition is notable therewith. The detection rates in 2's and 3's were also solid, but they were abysmal for detecting 4's. It is tough to detect 4's in general, as there are few trees that lead there, but alas there should be some. Overall, for our worst classifier, kNN performed adaquetly.\n",
    "\n",
    "### Decision Tree Classification\n",
    "Moving to decision trees, we decided to run two separate subprojects.\n",
    "\n",
    "The first subproject (found in [decision_tree.ipynb](decision_tree.ipynb)) helped with testing, and let us flex our pruning muscles. We used this to decide our splits, to make them interesting, and this is how we got the \\_4444 splits. We manually pruned [this tree](tree_vis/_4444_tree.pdf) to get [this tree](tree_vis/_4444_tree_pruned.pdf); A good contrast. Because we used the whole dataset to build the former, we decided not to run tests upon this tree, instead using unpruned trees for our testing. On a side note, some of the alternate trees we got with Scoring Margin were, um, [bad](tree_vis/24444_tree.pdf). It was a good call to drop Scoring Margin.\n",
    "\n",
    "The second subproject involved actually testing out decision tree results using our defined function. Using the \\_4444 format, we came out with these results:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Predictive Accuracy: 0.562\n",
    "Error Rate: 0.438\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "===========  ===  ===  ===  ===  =======  ==================\n",
    "  Win% Tier    1    2    3    4    Total    Recognition (%%)\n",
    "===========  ===  ===  ===  ===  =======  ==================\n",
    "          1    6   25    3    0       34               17.65\n",
    "          2    8   60   46    2      116               51.72\n",
    "          3    0   33  120    4      157               76.43\n",
    "          4    0    3   25    5       33               15.15\n",
    "===========  ===  ===  ===  ===  =======  =================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excuse the difference in formatting; It's a result of us splitting up the work even to the most minor of problems.\n",
    "\n",
    "Anyway, here we see that the dataset worked well at detecting 3's, which by the distributions shown, were proven to be (ever so slightly) the most populous group, with 2's leading right behind. This suggests the classifier is good at detecting prevelent cases as themself, and terrible at pointing out fringe cases, as shown by the bad detection results above. To improve this in the future, we'd implement automatic pruning.\n",
    "\n",
    "### Random Forest Classification\n",
    "On to our ensemble classifier, Random Forests. We implemented Forests with two varying aspects for randomization: Attributes used and subdataset used. Let's go over each.\n",
    "\n",
    "For the problem of using attributes, I (Ben) decided to implement my own strategy to get a good mix, but with weight towards using all the attributes. It's the following, as mentioned in [myclassifiers.py](mysklearn/myclassifiers.py):\n",
    "\n",
    "    # 1. Set n to num_atts\n",
    "    # 2. If n == min_atts, return the current atts\n",
    "    # 3. Flip a coin, heads or tails\n",
    "    # 4. If heads, return the current attributes\n",
    "    # 5. Otherwise:\n",
    "    # 6.   Remove a random attribute from the list\n",
    "    # 7.   n -= 1\n",
    "    # 8.   Repeat from Step 2 onwards\n",
    "    \n",
    "Essentially, we wanted a formula that continuously split the odds in half of using the set as is or not. This was successful, as we got a generally good number of removals via testing in our [testing file](random_forest.ipnyb) (About half included them, as verified through prints).\n",
    "\n",
    "As for the latter problem, we implemented bagging. Not much to see here, though it should be noted we stored validation accuracy, in order to implement optional weighted voting. In essence, if the user wanted to weight the votes of accurate \"experts\" over the common citizenry, they could set weighted=True, and each vote would be multiplied by the validation accuracy. Upon testing this, there wasn't a noticeable difference in accuracy, so we didn't use it for our testing.\n",
    "\n",
    "We ran trials from seeds 10-15, and found Random Forests had an approximate average accuracy of 57%, contributed to by the following run on seed 15:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Predictive Accuracy: 0.582\n",
    "Error Rate: 0.418\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "===========  ===  ===  ===  ===  =======  ==================\n",
    "  Win% Tier    1    2    3    4    Total    Recognition (%%)\n",
    "===========  ===  ===  ===  ===  =======  ==================\n",
    "          1    6   25    3    0       34               17.65\n",
    "          2    4   65   45    2      116               56.03\n",
    "          3    0   31  121    5      157               77.07\n",
    "          4    0    2   25    6       33               18.18\n",
    "===========  ===  ===  ===  ===  =======  =================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably see, this is very similar to the Decision Tree classifier's results, which makes a ton of sense! We decided also to use m=10 and n=50, giving a community of experts approach. This was our best result (though not by much), and we used it for our Heroku rollout.\n",
    "\n",
    "Before that, a reminder that you can find all this work on [classification_eval.ipynb](classification_eval.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heroku Rollout of Random Forests\n",
    "Here's our Heroku web app. It hasn't got much in terms of bells and whistles, but it works! __TODO__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We conclude that the attributes and advanced statistics we used were very helpful in finding classifications. While there is some degree of variability in a team's winning percentage, these 3 or 4 attributes really help to decipher such performance's occurance.\n",
    "\n",
    "The data we used was from [the NCAA Statistics Page and API](http://stats.ncaa.org/rankings/change_sport_year_div). We simply moved the API data from the site to Excel sheets, which were converted into csv files via Windows Excel. From there, we did all the work explained about this section. There were no problems for classification.\n",
    "\n",
    "For our approach and challenges, I have to say candidly, we crushed the splitting of work and accomplishing our set tasks. Each of us did equal parts and communicated when they were done, leading to a smooth rollout. Here's the list of who did what:\n",
    "\n",
    "Brandon:\n",
    "- Put together data from API\n",
    "- Exploratory Data Analysis\n",
    "- kNN implementation\n",
    "- Heroku implementation and creation\n",
    "\n",
    "Ben:\n",
    "- Statistic Parsing\n",
    "- Discretization and Normalization\n",
    "- Decision Tree implementation\n",
    "- Random Forest implementation\n",
    "  \n",
    "The challenges we ran into were technicalities, such as some bugs in our Heroku setup, struggles to normalize the data (given my (Ben's) faulty myutils functions up to that point) and git merges. Though we were able to get through them fairly steadily.\n",
    "\n",
    "To improve the performance, we think adding pruning to the decision trees and therefore the random forests would help a ton. Additionally, we could expand the scope of our data beyond the current season. This would have been fairly easy, though tedious in setup and in computational time.\n",
    "\n",
    "If you have any questions, feel free to shoot either of us a message through your preferred service. Have a great summer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
