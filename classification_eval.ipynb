{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Evaluation\n",
    "## Classifier 1: Decision Tree (unpruned, \\_4444 attributes)\n",
    "\n",
    "We're evaluating the natural, \\_4444 format of the classifier, meaning without considering Scoring Margin and using 4 bins for all the attributes and for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive Accuracy: 0.462\n",
      "Error Rate: 0.538\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "=====  ===  ===  ===  ===  =======  ==================\n",
      "  MPG    1    2    3    4    Total    Recognition (%%)\n",
      "=====  ===  ===  ===  ===  =======  ==================\n",
      "    1   54    8    6    1       69               78.26\n",
      "    2   35   25   12    9       81               30.86\n",
      "    3   23   24   26   28      101               25.74\n",
      "    4    3    9   25   52       89               58.43\n",
      "=====  ===  ===  ===  ===  =======  ==================\n"
     ]
    }
   ],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier\n",
    "\n",
    "import copy\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "header, data = myutils.load_from_file(\"input_data/NCAA_Statistics_24444.csv\")\n",
    "\n",
    "# Now, we can move to create some decision trees. Let's first create trees over the whole dataset, then\n",
    "# test upon our stratisfied k-fold splitting method.\n",
    "\n",
    "class_col = myutils.get_column(data, header, \"Win Percentage\")\n",
    "data = myutils.drop_column(data, header, \"Win Percentage\")\n",
    "data = myutils.drop_column(data, header, \"Scoring Margin\")\n",
    "atts = header[1:-1]\n",
    "\n",
    "# Let's stratisfy\n",
    "X_indices = range(len(class_col))\n",
    "X_train_folds, X_test_folds = myevaluation.stratified_kfold_cross_validation(X_indices, class_col, n_splits=10)\n",
    "\n",
    "y_preds = []\n",
    "y_reals = []\n",
    "correct = 0\n",
    "total = 0\n",
    "    \n",
    "for fold_index in range(len(X_train_folds)):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    for train_index in X_train_folds[fold_index]:\n",
    "        X_train.append(copy.deepcopy(data[train_index]))\n",
    "        y_train.append(copy.deepcopy(class_col[train_index]))\n",
    "        \n",
    "    for test_index in X_test_folds[fold_index]:\n",
    "        X_test.append(copy.deepcopy(data[test_index]))\n",
    "        y_test.append(copy.deepcopy(class_col[test_index]))\n",
    "        \n",
    "    # Get a classifier in here...\n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "\n",
    "    # Fitting...\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    # ... and predicting!\n",
    "    y_pred = my_dt.predict(X_test)\n",
    "    \n",
    "    # Counting and recording...\n",
    "    for i in range(len(y_pred)):\n",
    "        total += 1\n",
    "        if y_pred[i] == y_test[i]:\n",
    "            correct += 1\n",
    "            \n",
    "        y_preds.append(copy.deepcopy(y_pred[i]))\n",
    "        y_reals.append(copy.deepcopy(y_test[i]))\n",
    "        \n",
    "print(\"Predictive Accuracy:\", str(round(correct / total, 3)))\n",
    "print(\"Error Rate:\", str(1 - round(correct / total, 3)))\n",
    "print()\n",
    "print(\"Confusion Matrix:\")\n",
    "print()\n",
    "\n",
    "labels = [\"1\", \"2\", \"3\", \"4\"]\n",
    "conf_matrix = myevaluation.confusion_matrix(y_reals, y_preds, labels)\n",
    "\n",
    "for index in range(len(conf_matrix)):\n",
    "    conf_matrix[index].append(sum(conf_matrix[index]))\n",
    "    if conf_matrix[index][-1] == 0:\n",
    "        conf_matrix[index].append(0)\n",
    "    else:\n",
    "        conf_matrix[index].append(round(100 * conf_matrix[index][index] / conf_matrix[index][-1], 2))\n",
    "    conf_matrix[index] = [index+1] + conf_matrix[index]\n",
    "    \n",
    "header = [\"MPG\"]\n",
    "for index in labels:\n",
    "    header.append(index)\n",
    "header.append(\"Total\")\n",
    "header.append(\"Recognition (%%)\")\n",
    "\n",
    "print(tabulate(conf_matrix, headers=header, tablefmt=\"rst\", numalign=\"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
