{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Evaluation\n",
    "## Classifier 1: Decision Tree (unpruned, \\_4444 attributes)\n",
    "\n",
    "We're evaluating the natural, \\_4444 format of the classifier, meaning without considering Scoring Margin and using 4 bins for all the attributes and for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictive Accuracy: 0.562\nError Rate: 0.43799999999999994\n\nConfusion Matrix:\n\n===========  ===  ===  ===  ===  =======  ==================\n  Win% Tier    1    2    3    4    Total    Recognition (%%)\n===========  ===  ===  ===  ===  =======  ==================\n          1    6   25    3    0       34               17.65\n          2    8   60   46    2      116               51.72\n          3    0   33  120    4      157               76.43\n          4    0    3   25    5       33               15.15\n===========  ===  ===  ===  ===  =======  ==================\n"
     ]
    }
   ],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier, MyKNeighborsClassifier\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import copy\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "header, data = myutils.load_from_file(\"input_data/NCAA_Statistics_24444.csv\")\n",
    "\n",
    "# Now, we can move to create some decision trees. Let's first create trees over the whole dataset, then\n",
    "# test upon our stratisfied k-fold splitting method.\n",
    "\n",
    "class_col = myutils.get_column(data, header, \"Win Percentage\")\n",
    "data = myutils.drop_column(data, header, \"Win Percentage\")\n",
    "data = myutils.drop_column(data, header, \"Scoring Margin\")\n",
    "atts = header[1:-1]\n",
    "\n",
    "# Let's stratisfy\n",
    "X_indices = range(len(class_col))\n",
    "X_train_folds, X_test_folds = myevaluation.stratified_kfold_cross_validation(X_indices, class_col, n_splits=10)\n",
    "\n",
    "y_preds = []\n",
    "y_reals = []\n",
    "correct = 0\n",
    "total = 0\n",
    "    \n",
    "for fold_index in range(len(X_train_folds)):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    for train_index in X_train_folds[fold_index]:\n",
    "        X_train.append(copy.deepcopy(data[train_index]))\n",
    "        y_train.append(copy.deepcopy(class_col[train_index]))\n",
    "        \n",
    "    for test_index in X_test_folds[fold_index]:\n",
    "        X_test.append(copy.deepcopy(data[test_index]))\n",
    "        y_test.append(copy.deepcopy(class_col[test_index]))\n",
    "        \n",
    "    # Get a classifier in here...\n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "\n",
    "    # Fitting...\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    # ... and predicting!\n",
    "    y_pred = my_dt.predict(X_test)\n",
    "    \n",
    "    # Counting and recording...\n",
    "    for i in range(len(y_pred)):\n",
    "        total += 1\n",
    "        if y_pred[i] == y_test[i]:\n",
    "            correct += 1\n",
    "            \n",
    "        y_preds.append(copy.deepcopy(y_pred[i]))\n",
    "        y_reals.append(copy.deepcopy(y_test[i]))\n",
    "        \n",
    "print(\"Predictive Accuracy:\", str(round(correct / total, 3)))\n",
    "print(\"Error Rate:\", str(1 - round(correct / total, 3)))\n",
    "print()\n",
    "print(\"Confusion Matrix:\")\n",
    "print()\n",
    "\n",
    "labels = [\"1\", \"2\", \"3\", \"4\"]\n",
    "conf_matrix = myevaluation.confusion_matrix(y_reals, y_preds, labels)\n",
    "\n",
    "for index in range(len(conf_matrix)):\n",
    "    conf_matrix[index].append(sum(conf_matrix[index]))\n",
    "    if conf_matrix[index][-1] == 0:\n",
    "        conf_matrix[index].append(0)\n",
    "    else:\n",
    "        conf_matrix[index].append(round(100 * conf_matrix[index][index] / conf_matrix[index][-1], 2))\n",
    "    conf_matrix[index] = [index+1] + conf_matrix[index]\n",
    "    \n",
    "header = [\"Win% Tier\"]\n",
    "for index in labels:\n",
    "    header.append(index)\n",
    "header.append(\"Total\")\n",
    "header.append(\"Recognition (%%)\")\n",
    "\n",
    "print(tabulate(conf_matrix, headers=header, tablefmt=\"rst\", numalign=\"right\"))"
   ]
  },
  {
   "source": [
    "## Classifier 2: K Nearest Neighbors\n",
    "\n",
    "We're evaluating the natural, \\_4444 format of the classifier, meaning without considering Scoring Margin and using 4 bins for all the attributes and for the classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nKNN: accuracy = 0.5294117647058824, error rate = 0.47058823529411764\n\n  Win% Tier    1    2    3    4    total    Recognition (%)\n-----------  ---  ---  ---  ---  -------  -----------------\n          1   24    9    1    0       34           70.5882\n          2   28   69   19    0      116           59.4828\n          3    2   68   84    3      157           53.5032\n          4    0    8   22    3       33            9.09091\n\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(myutils)\n",
    "\n",
    "ncaa_path = os.path.join(\"input_data\",\"NCAA_Statistics_24444.csv\")\n",
    "ncaa_data = MyPyTable().load_from_file(ncaa_path)\n",
    "win_percentage = ncaa_data.get_column(\"Win Percentage\")\n",
    "scoring_margin = ncaa_data.get_column(\"Scoring Margin\")\n",
    "efg = ncaa_data.get_column(\"eFG%\")\n",
    "spg_bpg = ncaa_data.get_column(\"SPG+BPG\")\n",
    "Rebound_margin = ncaa_data.get_column(\"Rebound Margin\")\n",
    "\n",
    "X_indices = range(len(win_percentage))\n",
    "X_train_folds, X_test_folds = myevaluation.stratified_kfold_cross_validation(X_indices,win_percentage,n_splits=10)\n",
    "\n",
    "\n",
    "knn = MyKNeighborsClassifier(n_neighbors=10)\n",
    "knn_predictions = []\n",
    "knn_actual = []\n",
    "\n",
    "for i in range(len(X_train_folds)):\n",
    "    y_train_1 = []\n",
    "    X_train_1 = []\n",
    "    y_test_1 = []\n",
    "    X_test_1 = []\n",
    "    for index in X_train_folds[i]:\n",
    "        X_train_1.append([scoring_margin[index],efg[index],spg_bpg[index],Rebound_margin[index]])\n",
    "        y_train_1.append(win_percentage[index])\n",
    "    for index in X_test_folds[i]:\n",
    "        X_test_1.append([scoring_margin[index],efg[index],spg_bpg[index],Rebound_margin[index]])\n",
    "        y_test_1.append(win_percentage[index])\n",
    "    knn.fit(X_train_1,y_train_1)\n",
    "    knn_predictions.append(knn.predict(X_test_1))\n",
    "    knn_actual.append(y_test_1)\n",
    "\n",
    "knn_predictions_1d_1 = []\n",
    "for i in knn_predictions:\n",
    "    for k in i:\n",
    "        knn_predictions_1d_1.append(k)\n",
    "knn_actual_1d_1 = []\n",
    "for i in knn_actual:\n",
    "    for j in i:\n",
    "        knn_actual_1d_1.append(j)\n",
    "\n",
    "\n",
    "knn_total_correct = 0\n",
    "knn_total_predictions = len(knn_actual_1d_1)\n",
    "for i in range(len(knn_predictions_1d_1)):\n",
    "    if knn_predictions_1d_1[i] == knn_actual_1d_1[i]:\n",
    "        knn_total_correct += 1\n",
    "\n",
    "knn_accuracy = knn_total_correct /knn_total_predictions\n",
    "knn_error_rate = 1 - knn_accuracy \n",
    "\n",
    "print()\n",
    "print(\"KNN: \" +\"accuracy = \"+str(knn_accuracy)+ \", error rate = \" + str(knn_error_rate))\n",
    "\n",
    "column_names = [1,2,3,4]\n",
    "\n",
    "knn_matrix = myevaluation.confusion_matrix(knn_actual_1d_1,knn_predictions_1d_1,column_names)\n",
    "sum_matrix_1 = []\n",
    "for i in knn_matrix:\n",
    "    sum_matrix_1.append(sum(i))\n",
    "\n",
    "recognition_1 = []\n",
    "for i in range(len(knn_matrix)):\n",
    "    if sum_matrix_1[i] > 0:\n",
    "        recognition_1.append((knn_matrix[i][i] / sum_matrix_1[i]) * 100)\n",
    "    else:\n",
    "        recognition_1.append(0)\n",
    "\n",
    "for i in range(len(knn_matrix)):\n",
    "    knn_matrix[i].append(sum_matrix_1[i])\n",
    "for i in range(len(knn_matrix)):\n",
    "    knn_matrix[i].insert(0,column_names[i])\n",
    "for i in range(len(knn_matrix)):\n",
    "    knn_matrix[i].append(recognition_1[i])\n",
    "\n",
    "column_names_2= [\"Win% Tier\",1,2,3,4,\"total\",\"Recognition (%)\"]\n",
    "print()\n",
    "print(tabulate(knn_matrix,column_names_2))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}