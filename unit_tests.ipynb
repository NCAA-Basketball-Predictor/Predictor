{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview Tree Rules:\n",
      "IF level == Junior AND phd == no THEN interviewed_well = True\n",
      "IF level == Junior AND phd == yes THEN interviewed_well = False\n",
      "IF level == Mid THEN interviewed_well = True\n",
      "IF level == Senior AND tweets == no THEN interviewed_well = False\n",
      "IF level == Senior AND tweets == yes THEN interviewed_well = True\n",
      "\n",
      "Degrees Tree Rules:\n",
      "IF SoftEng == A AND Project == A THEN Class = FIRST\n",
      "IF SoftEng == A AND Project == B AND CSA == A AND ARIN == A THEN Class = FIRST\n",
      "IF SoftEng == A AND Project == B AND CSA == A AND ARIN == B THEN Class = SECOND\n",
      "IF SoftEng == A AND Project == B AND CSA == B THEN Class = SECOND\n",
      "IF SoftEng == B THEN Class = SECOND\n",
      "\n",
      "Interview Tree Rules with generic names:\n",
      "IF att0 == Junior AND att3 == no THEN class = True\n",
      "IF att0 == Junior AND att3 == yes THEN class = False\n",
      "IF att0 == Mid THEN class = True\n",
      "IF att0 == Senior AND att2 == no THEN class = False\n",
      "IF att0 == Senior AND att2 == yes THEN class = True\n",
      "\n",
      "Degrees Tree Rules with generic names:\n",
      "IF att0 == A AND att4 == A THEN class = FIRST\n",
      "IF att0 == A AND att4 == B AND att3 == A AND att1 == A THEN class = FIRST\n",
      "IF att0 == A AND att4 == B AND att3 == A AND att1 == B THEN class = SECOND\n",
      "IF att0 == A AND att4 == B AND att3 == B THEN class = SECOND\n",
      "IF att0 == B THEN class = SECOND\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unit Tests for knn and decision trees (find testing for RF's in random_forest.ipynb):\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "import math\n",
    "\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDecisionTreeClassifier\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "def test_kneighbors_classifier_kneighbors():\n",
    "    # Let's start by using the 4-instance training set example from lecture.\n",
    "    k = 3\n",
    "    four_X_train = [[7, 7], \\\n",
    "                    [7, 4], \\\n",
    "                    [3, 4], \\\n",
    "                    [1, 4]]\n",
    "    \n",
    "    four_y_train = [\"bad\", \\\n",
    "                    \"bad\", \\\n",
    "                    \"good\", \\\n",
    "                    \"good\"]\n",
    "    \n",
    "    four_test = [[3, 7]]\n",
    "    \n",
    "    four_mins, four_maxs = myutils.scale(four_X_train)\n",
    "    myutils.scale(four_test, zero_vals=four_mins, one_vals=four_maxs)\n",
    "    \n",
    "    our_k_neighbors = MyKNeighborsClassifier(n_neighbors=k)\n",
    "    our_k_neighbors.fit(four_X_train, four_y_train)\n",
    "    \n",
    "    # Now we can grab the info about the knn\n",
    "    four_distances, four_indices = our_k_neighbors.kneighbors(four_test)\n",
    "    \n",
    "    # From class, we can gather the desired results:\n",
    "    # I want these to be sorted least to most.\n",
    "    four_distances_desired = [[2/3, 1, (10/9) ** 0.5]]\n",
    "    four_indices_desired = [[0, 2, 3]]\n",
    "    \n",
    "    # Now we can check our implementation\n",
    "    for i in range(len(four_distances)):\n",
    "        for j in range(len(four_distances[i])):\n",
    "            assert math.isclose(four_distances[i][j], four_distances_desired[i][j])\n",
    "            assert math.isclose(four_indices[i][j], four_indices_desired[i][j])\n",
    "        \n",
    "    # Okay, now we can use the 8-instance sample\n",
    "    k = 3\n",
    "    eight_X_train = [[3, 2], \\\n",
    "                     [6, 6], \\\n",
    "                     [4, 1], \\\n",
    "                     [4, 4], \\\n",
    "                     [1, 2], \\\n",
    "                     [2, 0], \\\n",
    "                     [0, 3], \\\n",
    "                     [1, 6]]\n",
    "    \n",
    "    eight_y_train = [\"no\", \\\n",
    "                     \"yes\", \\\n",
    "                     \"no\", \\\n",
    "                     \"no\", \\\n",
    "                     \"yes\", \\\n",
    "                     \"no\", \\\n",
    "                     \"yes\", \\\n",
    "                     \"yes\"]\n",
    "    \n",
    "    eight_test = [[2, 3]]\n",
    "    \n",
    "    eight_mins, eight_maxs = myutils.scale(eight_X_train)\n",
    "    myutils.scale(eight_test, zero_vals=eight_mins, one_vals=eight_maxs)\n",
    "    \n",
    "    our_k_neighbors = MyKNeighborsClassifier(n_neighbors=k)\n",
    "    our_k_neighbors.fit(eight_X_train, eight_y_train)\n",
    "    \n",
    "    # Grabbing the distances...\n",
    "    eight_distances, eight_indices = our_k_neighbors.kneighbors(eight_test)\n",
    "    \n",
    "    # Now for our assertion distances and indices, we'll use basic math.\n",
    "    # I got the following Euclidean distances:\n",
    "    # sqrt(2), 5, 2*sqrt(2), sqrt(5), sqrt(2), 3, 2, sqrt(10)\n",
    "    # This should mean either index 0 or 4 is first. It depends on our sorting algorithm.\n",
    "    # For this purpose I'll implement a merge sort that breaks ties by using the lower index\n",
    "    # in my utils.py\n",
    "    eight_distances_desired = [[18 ** -0.5, 18 ** -0.5, 1/3]]\n",
    "    eight_indices_desired = [[4, 0, 6]]\n",
    "    \n",
    "    # Now for our assertions...\n",
    "    for i in range(len(eight_distances_desired)):\n",
    "        for j in range(len(eight_distances_desired[i])):\n",
    "            assert math.isclose(eight_distances[i][j], eight_distances_desired[i][j])\n",
    "            assert math.isclose(eight_indices[i][j], eight_indices_desired[i][j])\n",
    "        \n",
    "    # Let's check using the Bramer Figure 3.5 dataset for our training set...\n",
    "    k = 5\n",
    "    bramer_X_train = [[0.8, 6.3], \\\n",
    "                      [1.4, 8.1], \\\n",
    "                      [2.1, 7.4], \\\n",
    "                      [2.6, 14.3], \\\n",
    "                      [6.8, 12.6], \\\n",
    "                      [8.8, 9.8], \\\n",
    "                      [9.2, 11.6], \\\n",
    "                      [10.8, 9.6], \\\n",
    "                      [11.8, 9.9], \\\n",
    "                      [12.4, 6.5], \\\n",
    "                      [12.8, 1.1], \\\n",
    "                      [14.0, 19.9], \\\n",
    "                      [14.2, 18.5], \\\n",
    "                      [15.6, 17.4], \\\n",
    "                      [15.8, 12.2], \\\n",
    "                      [16.6, 6.7], \\\n",
    "                      [17.4, 4.5], \\\n",
    "                      [18.2, 6.9], \\\n",
    "                      [19.0, 3.4], \\\n",
    "                      [19.6, 11.1]]\n",
    "    \n",
    "    bramer_y_train = ['-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '+']\n",
    "    \n",
    "    bramer_test = [[9.1, 11.0]]\n",
    "    \n",
    "    # We won't scale this test.\n",
    "    \n",
    "    # Phew, done with that. Remind me never to take a job in data entry.\n",
    "    # Now we can use our own implementation.\n",
    "    our_k_neighbors = MyKNeighborsClassifier(n_neighbors=k)\n",
    "    our_k_neighbors.fit(bramer_X_train, bramer_y_train)\n",
    "    \n",
    "    # Grabbing the distances...\n",
    "    bramer_distances, bramer_indices = our_k_neighbors.kneighbors(bramer_test)\n",
    "    \n",
    "    bramer_distances_desired = [[.37 ** 0.5, 1.53 ** 0.5, 4.85 ** 0.5, 7.85 ** 0.5, 8.5 ** 0.5]]\n",
    "    bramer_indices_desired = [[6, 5, 7, 4, 8]]\n",
    "    \n",
    "    # And for our assertions...\n",
    "    for i in range(len(bramer_distances)):\n",
    "        for j in range(len(bramer_distances[i])):\n",
    "            assert math.isclose(bramer_distances[i][j], bramer_distances_desired[i][j])\n",
    "            assert math.isclose(bramer_indices[i][j], bramer_indices_desired[i][j])\n",
    "\n",
    "def test_kneighbors_classifier_predict():\n",
    "    # We can just copy-paste our earlier methods!\n",
    "    \n",
    "    # Let's start by using the 4-instance training set example from lecture.\n",
    "    k = 3\n",
    "    four_X_train = [[7, 7], \\\n",
    "                    [7, 4], \\\n",
    "                    [3, 4], \\\n",
    "                    [1, 4]]\n",
    "    \n",
    "    four_y_train = [\"bad\", \\\n",
    "                    \"bad\", \\\n",
    "                    \"good\", \\\n",
    "                    \"good\"]\n",
    "    \n",
    "    four_test = [[3, 7]]\n",
    "    \n",
    "    four_mins, four_maxs = myutils.scale(four_X_train)\n",
    "    myutils.scale(four_test, zero_vals=four_mins, one_vals=four_maxs)\n",
    "    \n",
    "    our_k_neighbors = MyKNeighborsClassifier(n_neighbors=k)\n",
    "    our_k_neighbors.fit(four_X_train, four_y_train)\n",
    "    \n",
    "    # Now we can grab the info about the knn\n",
    "    four_distances, four_indices = our_k_neighbors.kneighbors(four_test)\n",
    "    \n",
    "    # From class, we can gather the desired results:\n",
    "    # I want these to be sorted least to most.\n",
    "    four_distances_desired = [[2/3, 1, (10/9) ** 0.5]]\n",
    "    four_indices_desired = [[0, 2, 3]]\n",
    "    \n",
    "    # We'll assume the previous check passes, so let's now use predict().\n",
    "    # We expect a \"good\" classification with k=3\n",
    "    assert our_k_neighbors.predict(four_test) == [\"good\"]\n",
    "        \n",
    "    # Okay, now we can use the 8-instance sample\n",
    "    k = 3\n",
    "    eight_X_train = [[3, 2], \\\n",
    "                     [6, 6], \\\n",
    "                     [4, 1], \\\n",
    "                     [4, 4], \\\n",
    "                     [1, 2], \\\n",
    "                     [2, 0], \\\n",
    "                     [0, 3], \\\n",
    "                     [1, 6]]\n",
    "    \n",
    "    eight_y_train = [\"no\", \\\n",
    "                     \"yes\", \\\n",
    "                     \"no\", \\\n",
    "                     \"no\", \\\n",
    "                     \"yes\", \\\n",
    "                     \"no\", \\\n",
    "                     \"yes\", \\\n",
    "                     \"yes\"]\n",
    "    \n",
    "    eight_test = [[2, 3]]\n",
    "    \n",
    "    eight_mins, eight_maxs = myutils.scale(eight_X_train)\n",
    "    myutils.scale(eight_test, zero_vals=eight_mins, one_vals=eight_maxs)\n",
    "    \n",
    "    our_k_neighbors = MyKNeighborsClassifier(n_neighbors=k)\n",
    "    our_k_neighbors.fit(eight_X_train, eight_y_train)\n",
    "    \n",
    "    # Grabbing the distances...\n",
    "    eight_distances, eight_indices = our_k_neighbors.kneighbors(eight_test)\n",
    "    \n",
    "    # Now for our assertion distances and indices, we'll use basic math.\n",
    "    # I got the following Euclidean distances:\n",
    "    # sqrt(2), 5, 2*sqrt(2), sqrt(5), sqrt(2), 3, 2, sqrt(10)\n",
    "    # This should mean either index 0 or 4 is first. It depends on our sorting algorithm.\n",
    "    # For this purpose I'll implement a merge sort that breaks ties by using the lower index\n",
    "    # in my utils.py\n",
    "    eight_distances_desired = [[18 ** -0.5, 18 ** -0.5, 1/3]]\n",
    "    eight_indices_desired = [[0, 4, 6]]\n",
    "    \n",
    "    # We'll assume the previous check passes, so let's now use predict().\n",
    "    # We expect a \"yes\" classification with k=3\n",
    "    assert our_k_neighbors.predict(eight_test) == [\"yes\"]\n",
    "        \n",
    "    # Let's check using the Bramer Figure 3.5 dataset for our training set...\n",
    "    k = 5\n",
    "    bramer_X_train = [[0.8, 6.3], \\\n",
    "                      [1.4, 8.1], \\\n",
    "                      [2.1, 7.4], \\\n",
    "                      [2.6, 14.3], \\\n",
    "                      [6.8, 12.6], \\\n",
    "                      [8.8, 9.8], \\\n",
    "                      [9.2, 11.6], \\\n",
    "                      [10.8, 9.6], \\\n",
    "                      [11.8, 9.9], \\\n",
    "                      [12.4, 6.5], \\\n",
    "                      [12.8, 1.1], \\\n",
    "                      [14.0, 19.9], \\\n",
    "                      [14.2, 18.5], \\\n",
    "                      [15.6, 17.4], \\\n",
    "                      [15.8, 12.2], \\\n",
    "                      [16.6, 6.7], \\\n",
    "                      [17.4, 4.5], \\\n",
    "                      [18.2, 6.9], \\\n",
    "                      [19.0, 3.4], \\\n",
    "                      [19.6, 11.1]]\n",
    "    \n",
    "    bramer_y_train = ['-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '-', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '+', \\\n",
    "                      '-', \\\n",
    "                      '+']\n",
    "    \n",
    "    bramer_test = [[9.1, 11.0]]\n",
    "    \n",
    "    # Phew, done with that. Remind me never to take a job in data entry.\n",
    "    # Now we can use our own implementation.\n",
    "    our_k_neighbors = MyKNeighborsClassifier(n_neighbors=k)\n",
    "    our_k_neighbors.fit(bramer_X_train, bramer_y_train)\n",
    "    \n",
    "    # We'll assume the previous check passes, so let's now use predict().\n",
    "    # We expect a \"good\" classification with k=3\n",
    "    assert our_k_neighbors.predict(bramer_test) == ['+']\n",
    "    \n",
    "def test_decision_tree_classifier_fit():\n",
    "    interview_header = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "    interview_table = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\", \"False\"]\n",
    "    ]\n",
    "    \n",
    "    interview_tree = \\\n",
    "        [\"Attribute\", \"att0\",\n",
    "            [\"Value\", \"Junior\", \n",
    "                [\"Attribute\", \"att3\",\n",
    "                    [\"Value\", \"no\", \n",
    "                        [\"Leaf\", \"True\", 3, 5]\n",
    "                    ],\n",
    "                    [\"Value\", \"yes\", \n",
    "                        [\"Leaf\", \"False\", 2, 5]\n",
    "                    ]\n",
    "                ]\n",
    "            ],\n",
    "            [\"Value\", \"Mid\",\n",
    "                [\"Leaf\", \"True\", 4, 14]\n",
    "            ],\n",
    "            [\"Value\", \"Senior\",\n",
    "                [\"Attribute\", \"att2\",\n",
    "                    [\"Value\", \"no\",\n",
    "                        [\"Leaf\", \"False\", 3, 5]\n",
    "                    ],\n",
    "                    [\"Value\", \"yes\",\n",
    "                        [\"Leaf\", \"True\", 2, 5]\n",
    "                    ]\n",
    "                ]\n",
    "            ]\n",
    "        ]\n",
    "    \n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    interview_table = myutils.drop_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    X_train = interview_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    assert myutils.equivalent(my_dt.tree, interview_tree) # Above this function\n",
    "    \n",
    "    # bramer degrees dataset\n",
    "    degrees_header = [\"SoftEng\", \"ARIN\", \"HCI\", \"CSA\", \"Project\", \"Class\"]\n",
    "    degrees_table = [\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"B\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"A\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"A\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "    ]\n",
    "\n",
    "    # Computed using entropy; This won't work until this is implemented\n",
    "    # This took me an hour, but near the end it got easy. I'm glad computers exist.\n",
    "    degrees_tree = \\\n",
    "        [\"Attribute\", \"att0\",\n",
    "            [\"Value\", \"A\",\n",
    "                [\"Attribute\", \"att4\",\n",
    "                    [\"Value\", \"A\",\n",
    "                        [\"Leaf\", \"FIRST\", 5, 14]\n",
    "                    ],\n",
    "                    [\"Value\", \"B\",\n",
    "                        [\"Attribute\", \"att3\",\n",
    "                            [\"Value\", \"A\", \n",
    "                                [\"Attribute\", \"att1\", \n",
    "                                    [\"Value\", \"A\", \n",
    "                                        [\"Leaf\", \"FIRST\", 1, 2]\n",
    "                                    ],\n",
    "                                    [\"Value\", \"B\",\n",
    "                                        [\"Leaf\", \"SECOND\", 1, 2]\n",
    "                                    ]\n",
    "                                ]\n",
    "                            ],\n",
    "                            [\"Value\", \"B\",\n",
    "                                [\"Leaf\", \"SECOND\", 7, 9]\n",
    "                            ]\n",
    "                        ]\n",
    "                    ]\n",
    "                ]\n",
    "            ],\n",
    "            [\"Value\", \"B\",\n",
    "                [\"Leaf\", \"SECOND\", 12, 26]\n",
    "            ]\n",
    "        ]\n",
    "    \n",
    "    # Same thing this time\n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(degrees_table, degrees_header, \"Class\")\n",
    "    degrees_table = myutils.drop_column(degrees_table, degrees_header, \"Class\")\n",
    "    X_train = degrees_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    assert myutils.equivalent(my_dt.tree, degrees_tree)\n",
    "\n",
    "def test_decision_tree_classifier_predict():\n",
    "    interview_header = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "    interview_table = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\", \"False\"]\n",
    "    ]\n",
    "    \n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    interview_table = myutils.drop_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    X_train = interview_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = [[\"Junior\", \"Java\", \"yes\", \"no\"],\n",
    "              [\"Junior\", \"Java\", \"yes\", \"yes\"]]\n",
    "    y_test = [\"True\", \"False\"]\n",
    "    \n",
    "    assert myutils.equivalent(my_dt.predict(X_test), y_test)\n",
    "    \n",
    "    # bramer degrees dataset\n",
    "    degrees_header = [\"SoftEng\", \"ARIN\", \"HCI\", \"CSA\", \"Project\", \"Class\"]\n",
    "    degrees_table = [\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"B\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"A\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"A\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "    ]\n",
    "    \n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(degrees_table, degrees_header, \"Class\")\n",
    "    degrees_table = myutils.drop_column(degrees_table, degrees_header, \"Class\")\n",
    "    X_train = degrees_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = [\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"B\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"B\"]\n",
    "    ]\n",
    "    y_test = [\"SECOND\", \"FIRST\", \"FIRST\"]\n",
    "    \n",
    "    assert myutils.equivalent(my_dt.predict(X_test), y_test)\n",
    "    \n",
    "    # After this we can feel pretty darn good about our implementation.\n",
    "    # Because it was tricky I'm going to run a good few more tests on the back end.\n",
    "    \n",
    "def test_decision_tree_classifier_print_rules():\n",
    "    interview_header = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "    interview_table = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\", \"False\"]\n",
    "    ]\n",
    "    \n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    interview_table = myutils.drop_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    X_train = interview_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Interview Tree Rules:\")\n",
    "    my_dt.print_decision_rules(interview_header[:-1], interview_header[-1])\n",
    "    print()\n",
    "    \n",
    "    # bramer degrees dataset\n",
    "    degrees_header = [\"SoftEng\", \"ARIN\", \"HCI\", \"CSA\", \"Project\", \"Class\"]\n",
    "    degrees_table = [\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"B\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"A\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"A\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "    ]\n",
    "    \n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(degrees_table, degrees_header, \"Class\")\n",
    "    degrees_table = myutils.drop_column(degrees_table, degrees_header, \"Class\")\n",
    "    X_train = degrees_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Degrees Tree Rules:\")\n",
    "    my_dt.print_decision_rules(degrees_header[:-1], degrees_header[-1])\n",
    "    print()\n",
    "    \n",
    "    interview_header = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "    interview_table = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\", \"False\"]\n",
    "    ]\n",
    "    \n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    interview_table = myutils.drop_column(interview_table, interview_header, \"interviewed_well\")\n",
    "    X_train = interview_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Interview Tree Rules with generic names:\")\n",
    "    my_dt.print_decision_rules()\n",
    "    print()\n",
    "    \n",
    "    # bramer degrees dataset\n",
    "    degrees_header = [\"SoftEng\", \"ARIN\", \"HCI\", \"CSA\", \"Project\", \"Class\"]\n",
    "    degrees_table = [\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"A\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"B\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"A\", \"B\", \"A\", \"A\", \"FIRST\"],\n",
    "        [\"B\", \"B\", \"B\", \"A\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"A\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"B\", \"B\", \"B\", \"A\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"A\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"A\", \"FIRST\"],\n",
    "        [\"A\", \"B\", \"A\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"B\", \"A\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "        [\"A\", \"B\", \"B\", \"B\", \"B\", \"SECOND\"],\n",
    "    ]\n",
    "    \n",
    "    my_dt = MyDecisionTreeClassifier()\n",
    "    y_train = myutils.get_column(degrees_table, degrees_header, \"Class\")\n",
    "    degrees_table = myutils.drop_column(degrees_table, degrees_header, \"Class\")\n",
    "    X_train = degrees_table\n",
    "    my_dt.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Degrees Tree Rules with generic names:\")\n",
    "    my_dt.print_decision_rules()\n",
    "    print()\n",
    "    \n",
    "#test_kneighbors_classifier_kneighbors() # Working on this, implementation differences are impacting this a bit\n",
    "#test_kneighbors_classifier_predict()\n",
    "test_decision_tree_classifier_fit()\n",
    "test_decision_tree_classifier_predict()\n",
    "test_decision_tree_classifier_print_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
