{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification\n",
    "\n",
    "We're going to use a couple of different input files that have been discretized to create some decision trees. I want to test it on the following sets of num_bins:\n",
    "\n",
    "22224\n",
    "24444\n",
    "55554\n",
    "\n",
    "We'll go into more in the future, with some Random Forest shenanigans, but for now we'll just use these. Let's load up some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "header1, data1 = myutils.load_from_file(\"input_data/NCAA_Statistics_22224.csv\")\n",
    "header2, data2 = myutils.load_from_file(\"input_data/NCAA_Statistics_24444.csv\")\n",
    "header3, data3 = myutils.load_from_file(\"input_data/NCAA_Statistics_55554.csv\")\n",
    "\n",
    "# Now, we can move to create some decision trees. Let's first create trees over the whole dataset, then\n",
    "# test upon our stratisfied k-fold splitting method.\n",
    "\n",
    "# PART 1: Whole datasets\n",
    "class_col1 = myutils.get_column(data1, header1, \"Win Percentage\")\n",
    "class_col2 = myutils.get_column(data2, header2, \"Win Percentage\")\n",
    "class_col3 = myutils.get_column(data3, header3, \"Win Percentage\")\n",
    "\n",
    "data1 = myutils.drop_column(data1, header1, \"Win Percentage\")\n",
    "data2 = myutils.drop_column(data2, header2, \"Win Percentage\")\n",
    "data3 = myutils.drop_column(data3, header3, \"Win Percentage\")\n",
    "\n",
    "atts1 = header1[:-1]\n",
    "atts2 = header2[:-1]\n",
    "atts3 = header3[:-1]\n",
    "\n",
    "# Get some classifiers in here...\n",
    "my_dt1 = MyDecisionTreeClassifier()\n",
    "my_dt2 = MyDecisionTreeClassifier()\n",
    "my_dt3 = MyDecisionTreeClassifier()\n",
    "\n",
    "# Fitting... they look good at first glance.\n",
    "my_dt1.fit(data1, class_col1)\n",
    "my_dt2.fit(data2, class_col2)\n",
    "my_dt3.fit(data3, class_col3)\n",
    "\n",
    "# Visualizing...\n",
    "my_dt1.visualize_tree(\"tree_vis/22224_tree.dot\", \"tree_vis/22224_tree.pdf\", atts1)\n",
    "my_dt2.visualize_tree(\"tree_vis/24444_tree.dot\", \"tree_vis/24444_tree.pdf\", atts2)\n",
    "my_dt3.visualize_tree(\"tree_vis/55554_tree.dot\", \"tree_vis/55554_tree.pdf\", atts3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graphs generated below [ADD THESE], It's easy to see the problem. Scoring Margin is such a strong indicator that it dominates the graph. Let's try taking the same data above but removing Scoring margin as an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyDecisionTreeClassifier\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "header1, data1 = myutils.load_from_file(\"input_data/NCAA_Statistics_22224.csv\")\n",
    "header2, data2 = myutils.load_from_file(\"input_data/NCAA_Statistics_24444.csv\")\n",
    "header3, data3 = myutils.load_from_file(\"input_data/NCAA_Statistics_55554.csv\")\n",
    "\n",
    "# Now, we can move to create some decision trees. Let's first create trees over the whole dataset, then\n",
    "# test upon our stratisfied k-fold splitting method.\n",
    "\n",
    "# PART 1: Whole datasets\n",
    "class_col1 = myutils.get_column(data1, header1, \"Win Percentage\")\n",
    "class_col2 = myutils.get_column(data2, header2, \"Win Percentage\")\n",
    "class_col3 = myutils.get_column(data3, header3, \"Win Percentage\")\n",
    "\n",
    "data1 = myutils.drop_column(data1, header1, \"Win Percentage\")\n",
    "data2 = myutils.drop_column(data2, header2, \"Win Percentage\")\n",
    "data3 = myutils.drop_column(data3, header3, \"Win Percentage\")\n",
    "\n",
    "data1 = myutils.drop_column(data1, header1, \"Scoring Margin\")\n",
    "data2 = myutils.drop_column(data2, header2, \"Scoring Margin\")\n",
    "data3 = myutils.drop_column(data3, header3, \"Scoring Margin\")\n",
    "\n",
    "atts1 = header1[1:-1]\n",
    "atts2 = header2[1:-1]\n",
    "atts3 = header3[1:-1]\n",
    "\n",
    "# Get some classifiers in here...\n",
    "my_dt1 = MyDecisionTreeClassifier()\n",
    "my_dt2 = MyDecisionTreeClassifier()\n",
    "my_dt3 = MyDecisionTreeClassifier()\n",
    "\n",
    "# Fitting... they look good at first glance.\n",
    "my_dt1.fit(data1, class_col1)\n",
    "my_dt2.fit(data2, class_col2)\n",
    "my_dt3.fit(data3, class_col3)\n",
    "\n",
    "# Visualizing...\n",
    "my_dt1.visualize_tree(\"tree_vis/_2224_tree.dot\", \"tree_vis/_2224_tree.pdf\", atts1)\n",
    "my_dt2.visualize_tree(\"tree_vis/_4444_tree.dot\", \"tree_vis/_4444_tree.pdf\", atts2)\n",
    "my_dt3.visualize_tree(\"tree_vis/_5554_tree.dot\", \"tree_vis/_5554_tree.pdf\", atts3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some testing on these new classifiers, with a bit less data to test with, using our stratisfied k-fold. In addition, I'll be using a manually-pruned tree my_dtp.tree to express the pruned version of tree 2 (with no Scoring Margin attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
